import streamlit as st
import pandas as pd
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from stop_words import get_stop_words

# È°µÈù¢ÈÖçÁΩÆ
st.set_page_config(page_title="Fake News Checker", page_icon="üß†")
st.title("üß† Fake-News Erkennung")
st.markdown(
    "Gib unten eine Aussage oder einen Tweet ein. "
    "Das System pr√ºft per TF-IDF + Cosine Similarity, "
    "ob der Text bekannten Fake News √§hnelt und gibt ein Ergebnis."
)

# ‚Äî‚Äî ‰æßËæπÊ†èÔºö‰∏ä‰º†ÂÅáÊñ∞ÈóªÂíåÊé®ÊñáÊñá‰ª∂ÔºàÊîØÊåÅ csv Âíå xlsxÔºâ ‚Äî‚Äî
st.sidebar.header("Daten hochladen")
fake_file = st.sidebar.file_uploader(
    "Fake-News Datei (CSV oder XLSX)", type=['csv','xlsx']
)
train_file = st.sidebar.file_uploader(
    "Tweets Datei (CSV oder XLSX)", type=['csv','xlsx']
)

if not fake_file or not train_file:
    st.warning("Bitte lade zuerst sowohl die Fake-News als auch die Tweets Datei hoch!")
    st.stop()

# ‚Äî‚Äî Ê†πÊçÆÂêéÁºÄËá™Âä®ËØªÂèñ ‚Äî‚Äî 
def load_df(file):
    name = file.name.lower()
    if name.endswith('.csv'):
        return pd.read_csv(file)
    elif name.endswith(('.xls','.xlsx')):
        return pd.read_excel(file, engine='openpyxl')
    else:
        st.error("Unbekanntes Dateiformat: " + name)
        st.stop()

df_fake  = load_df(fake_file)
df_train = load_df(train_file)

# ÊñáÊú¨È¢ÑÂ§ÑÁêÜ
df_fake ['text_clean'] = df_fake ['text']
df_train['text_clean'] = df_train['text']

# ‰∏¢ÂºÉÁ©∫ÂÄº
df_fake = df_fake.dropna(subset=['text_clean'])   
df_train = df_train.dropna(subset=['text_clean'])   

# Combine the corpora for fitting the TF-IDF vectorizer
combined_texts = df_fake['text'].tolist() + df_train['text_clean'].tolist()



# Load German stopwords via nltk

# ‚Äî‚Äî ÂèñÂá∫Âæ∑ËØ≠ÂÅúÁî®ËØçÂàóË°® ‚Äî‚Äî 
german_stopwords = get_stop_words('german')


# TF-IDF Áü¢ÈáèÂåñÔºàÂæ∑ËØ≠ÂÅúÁî®ËØçÔºâ
vectorizer = TfidfVectorizer(
    stop_words=german_stopwords,
    max_features=5000
)
fake_tfidf = vectorizer.fit_transform(df_fake['text_clean'].tolist())

# Áî®Êà∑ËæìÂÖ•
user_input = st.text_area(
    "üìù Deine Aussage oder Tweet",
    placeholder="z. B. 'Die Erde ist flach.'",
    height=150
)

# ÊåâÈíÆËß¶Âèë
if st.button("üîç Pr√ºfen"):
    text = user_input.strip()
    if not text:
        st.warning("Bitte gib einen Text ein.")
    else:
        # 1. ÂØπËæìÂÖ•ÊñáÊú¨ÂÅö TF-IDF
        input_tfidf = vectorizer.transform([text])
        # 2. ËÆ°ÁÆó‰ΩôÂº¶Áõ∏‰ººÂ∫¶Âπ∂ÂèñÊúÄÂ§ß
        sim_scores = cosine_similarity(input_tfidf, fake_tfidf)
        max_score  = sim_scores.max()
        # 3. Ê†πÊçÆÈòàÂÄºÊâìÊ†áÁ≠æ
        if max_score >= 0.7:
            label = "‚ùå Fake News"
        elif max_score <= 0.3:
            label = "‚úÖ Echte News"
        else:
            label = "‚ùì Unklar"
        # 4. ÊòæÁ§∫ÁªìÊûú
        st.markdown(f"### Ergebnis: {label}")
        st.write(f"√Ñhnlichkeitswert: {max_score:.3f}")
        # 5. ÂÅáÊñ∞ÈóªÊó∂ÁöÑËß£ÈáäÂç†‰Ωç
        if label.startswith("‚ùå"):
            st.markdown("### üßæ Erkl√§rung")
            st.info(
                "Der Text √§hnelt bekannten Fake News. "
                "Hier k√∂nnte sp√§ter ein LLM die genaue Falschbehauptung erl√§utern."
            )
